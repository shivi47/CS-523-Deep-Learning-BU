\documentclass{article}
\usepackage{graphicx}

\title{CS 523 Summer Semester 2, 2021: Problem Set 1}

\begin{document}
\maketitle
\textbf{Release Date}: Monday, July 12, 2021 at 00:00 EST\newline
\textbf{Due Date}: Wednesday, July 21, 2021 at 23:59 EST\newline
\textbf{Deliverables}: Your completed source code package in a \texttt{.zip} archive. Please remove any \texttt{\_\_pycache\_\_} directories. This will be submitted on Gradescope.\newline
\textbf{Reminder}: Please feel free to work together. If you collaborate with others, please write your team members names' in your submission.
\newline
\newline
In this class, we will be building our own neural network package in python using numpy as our linear algebra package. We will also be following a pytorch-esque design which I have already started. Your job is to complete the code in the following files and be able to run \texttt{test.py} successfully!
\newline
\newline
There are aspects of this problem set which will be covered during lecture while this assignment is out, so don't worry if this looks scary at the moment! Also, I highly encourage you to visit office hours if you have questions!
\newline
\newline
The following code files need to be completed:
\begin{enumerate}
    \item \texttt{nn/layers/sigmoid.py} (20pts)
    \item \texttt{nn/layers/tanh.py} (20pts)
    \item \texttt{nn/layers/dense.py} (40pts)
    \item \texttt{nn/losses/mse.py} (20pts)
\end{enumerate}

At the end of this assignment, you will be able to stack fully-connected (often called "feed-forward" or "dense") layers together using a (small) library of activation and loss functions! This is our first major step towards understanding neural networks!

\end{document}

